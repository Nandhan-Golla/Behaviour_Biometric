{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJCk-bulkbgK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    'user': ['User1'] * 50 + ['User2'] * 50 + ['User3'] * 50,\n",
        "    'avg_time': np.random.normal(loc=0.2, scale=0.05, size=150),\n",
        "    'std_dev_time': np.random.normal(loc=0.02, scale=0.01, size=150),\n",
        "}\n"
      ],
      "metadata": {
        "id": "HwkPCuNjk4Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "  'user' : ['User 1']*50 + ['User 2']*50 + ['User 3'] * 50,\n",
        "  'avg_time' : np.random.normal(loc=0.2, scale=0.05, size=150),\n",
        "  'std_dev_time' : np.random.normal(loc=0.02, scale=0.01, size=150)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['avg_time', 'std_dev_time']].values\n",
        "y = df['user'].values\n",
        "\n"
      ],
      "metadata": {
        "id": "D3NMlOcolATd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "X = df[['avg_time', 'std_dev_time']].values\n",
        "y = df['user'].values\n",
        "\n",
        "\n",
        "y = pd.factorize(y)[0]\n",
        "y = to_categorical(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f'X: {X}')\n",
        "print(f'y :{y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzbsYF9hlpOq",
        "outputId": "669f5fe3-55f7-4bb6-fd48-c6e3196cef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [[ 0.15855025  0.01937321]\n",
            " [ 0.17199095  0.02955142]\n",
            " [ 0.23736468  0.01014274]\n",
            " [ 0.23051851  0.02504047]\n",
            " [ 0.19895492  0.01469742]\n",
            " [ 0.20586637  0.01207127]\n",
            " [ 0.26388324  0.0189297 ]\n",
            " [ 0.17042143  0.00964758]\n",
            " [ 0.22735487  0.01446351]\n",
            " [ 0.18989037  0.00802122]\n",
            " [ 0.18911594  0.03964725]\n",
            " [ 0.25493884  0.02035264]\n",
            " [ 0.24127082  0.01300274]\n",
            " [ 0.24067548  0.0221398 ]\n",
            " [ 0.26527394  0.01887672]\n",
            " [ 0.20105019  0.0177903 ]\n",
            " [ 0.23409765  0.02614167]\n",
            " [ 0.18448666  0.02757508]\n",
            " [ 0.21620832  0.01469499]\n",
            " [ 0.19349285  0.01424182]\n",
            " [ 0.2048498   0.01724948]\n",
            " [ 0.22975785 -0.00301921]\n",
            " [ 0.15908897  0.00484809]\n",
            " [ 0.30461936  0.03366874]\n",
            " [ 0.14969913  0.03644968]\n",
            " [ 0.13929057  0.01750964]\n",
            " [ 0.25790554  0.02576557]\n",
            " [ 0.23958313  0.0231125 ]\n",
            " [ 0.23120599  0.05078881]\n",
            " [ 0.23141728  0.03119575]\n",
            " [ 0.19938766  0.01872082]\n",
            " [ 0.15513728  0.0104446 ]\n",
            " [ 0.20379023  0.00393554]\n",
            " [ 0.16614191  0.02203464]\n",
            " [ 0.24875599  0.01243649]\n",
            " [ 0.19264713  0.00577746]\n",
            " [ 0.15872514  0.01353427]\n",
            " [ 0.18393071  0.00918452]\n",
            " [ 0.22064657  0.03687142]\n",
            " [ 0.17181377  0.0288164 ]\n",
            " [ 0.15888898  0.01992027]\n",
            " [ 0.21218436  0.03479944]\n",
            " [ 0.21224833  0.02077368]\n",
            " [ 0.17465284  0.01138716]\n",
            " [ 0.17644808  0.03523124]\n",
            " [ 0.2116025   0.0253891 ]\n",
            " [ 0.12759578  0.00962754]\n",
            " [ 0.12962681  0.01809661]\n",
            " [ 0.16407779  0.01124382]\n",
            " [ 0.18932764  0.006172  ]\n",
            " [ 0.21554538  0.02926178]\n",
            " [ 0.27376781  0.03909417]\n",
            " [ 0.24288298  0.00601432]\n",
            " [ 0.19200307  0.02562969]\n",
            " [ 0.19904919  0.01349357]\n",
            " [ 0.14987353  0.01512875]\n",
            " [ 0.19907434  0.01407606]\n",
            " [ 0.18556707  0.01136009]\n",
            " [ 0.21613593  0.02048522]\n",
            " [ 0.15863845  0.0116905 ]\n",
            " [ 0.22596733  0.02270457]\n",
            " [ 0.27663695  0.01949762]\n",
            " [ 0.19456199  0.01761052]\n",
            " [ 0.22008559  0.01092436]\n",
            " [ 0.2345072   0.01423229]\n",
            " [ 0.17993898  0.02755391]\n",
            " [ 0.21120462  0.02500917]\n",
            " [ 0.20062962  0.01022445]\n",
            " [ 0.2048838   0.02099332]\n",
            " [ 0.16134951  0.02751387]\n",
            " [ 0.20122551  0.00330595]\n",
            " [ 0.22489991  0.0254336 ]\n",
            " [ 0.27255718  0.01337376]\n",
            " [ 0.24796354  0.02570599]\n",
            " [ 0.30765912  0.01236741]\n",
            " [ 0.16163262  0.00195118]\n",
            " [ 0.24361603  0.00372458]\n",
            " [ 0.2091671   0.02048085]\n",
            " [ 0.30949015  0.02259723]\n",
            " [ 0.15958509  0.01095683]\n",
            " [ 0.15801391  0.02638592]\n",
            " [ 0.17003037  0.0033848 ]\n",
            " [ 0.09380521  0.0193392 ]\n",
            " [ 0.17371225  0.00788984]\n",
            " [ 0.16204337  0.01348164]\n",
            " [ 0.20751969  0.02047399]\n",
            " [ 0.2170878   0.01139587]\n",
            " [ 0.29380854  0.01615444]\n",
            " [ 0.24752119  0.03006293]\n",
            " [ 0.17115482  0.01423108]\n",
            " [ 0.15507927  0.02835692]\n",
            " [ 0.22459596  0.00870293]\n",
            " [ 0.13398834  0.02529804]\n",
            " [ 0.29157294  0.03441569]\n",
            " [ 0.25897201 -0.00471645]\n",
            " [ 0.17654122  0.01203105]\n",
            " [ 0.11434327  0.02577072]\n",
            " [ 0.26769362  0.01796955]\n",
            " [ 0.19427301  0.02371146]\n",
            " [ 0.26189082  0.01396015]\n",
            " [ 0.12027862  0.0208659 ]\n",
            " [ 0.17003125  0.01844323]\n",
            " [ 0.20026218  0.03167782]\n",
            " [ 0.20234903  0.02254421]\n",
            " [ 0.17749673  0.02337603]\n",
            " [ 0.2311425   0.01588123]\n",
            " [ 0.14661898  0.01512394]\n",
            " [ 0.19288103  0.01567442]\n",
            " [ 0.20601478  0.02394452]\n",
            " [ 0.22572194  0.01579016]\n",
            " [ 0.23558074  0.02289775]\n",
            " [ 0.1437679   0.04075401]\n",
            " [ 0.12329429  0.02871125]\n",
            " [ 0.26388384  0.01673976]\n",
            " [ 0.2166157   0.03201214]\n",
            " [ 0.16257567  0.01591925]\n",
            " [ 0.2775576  -0.00038125]\n",
            " [ 0.20578373  0.00991914]\n",
            " [ 0.25896486  0.00129208]\n",
            " [ 0.20337592  0.01648487]\n",
            " [ 0.3030374   0.02018418]\n",
            " [ 0.28776704  0.03676437]\n",
            " [ 0.18755179  0.02326927]\n",
            " [ 0.24857855  0.01780899]\n",
            " [ 0.2322688   0.02829406]\n",
            " [ 0.26843158 -0.00211135]\n",
            " [ 0.15175383  0.02235615]\n",
            " [ 0.23430257  0.02770865]\n",
            " [ 0.25292122  0.00521414]\n",
            " [ 0.11206303  0.03143754]\n",
            " [ 0.14083707  0.02338496]\n",
            " [ 0.09803839  0.01584712]\n",
            " [ 0.18652966  0.02632782]\n",
            " [ 0.23587711  0.04270693]\n",
            " [ 0.27511785  0.02181866]\n",
            " [ 0.20370474  0.02248221]\n",
            " [ 0.28143078  0.01540639]\n",
            " [ 0.13099493  0.01150156]\n",
            " [ 0.11483088  0.02830336]\n",
            " [ 0.19722262  0.01143916]\n",
            " [ 0.21920327  0.02071566]\n",
            " [ 0.19836526  0.01522343]\n",
            " [ 0.09662789  0.0247898 ]\n",
            " [ 0.195544    0.02333662]\n",
            " [ 0.13477652  0.0303754 ]\n",
            " [ 0.23348363  0.01489984]\n",
            " [ 0.21832991  0.01730125]\n",
            " [ 0.15300601  0.01021236]\n",
            " [ 0.17430665  0.01555707]\n",
            " [ 0.14703932  0.023773  ]]\n",
            "y :[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz82Rv_dl4X4",
        "outputId": "5629f491-71a0-46bc-b8df-02c6b092c187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9YzayTJnxWW",
        "outputId": "a33dd998-c58f-4922-9d2e-6cc44c9a1b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHMzH1obnM1V",
        "outputId": "b478d057-658e-4e34-d9d6-4539d5c6a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4121 - loss: 1.0956 - val_accuracy: 0.1250 - val_loss: 1.2144\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3969 - loss: 1.1194 - val_accuracy: 0.1250 - val_loss: 1.2036\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3269 - loss: 1.0915 - val_accuracy: 0.1667 - val_loss: 1.1851\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3476 - loss: 1.1046 - val_accuracy: 0.1667 - val_loss: 1.1755\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3931 - loss: 1.1053 - val_accuracy: 0.2083 - val_loss: 1.1735\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3506 - loss: 1.1036 - val_accuracy: 0.2083 - val_loss: 1.1662\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3461 - loss: 1.1024 - val_accuracy: 0.1667 - val_loss: 1.1651\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4473 - loss: 1.0854 - val_accuracy: 0.1667 - val_loss: 1.1547\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3472 - loss: 1.0872 - val_accuracy: 0.1667 - val_loss: 1.1563\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4724 - loss: 1.0737 - val_accuracy: 0.1667 - val_loss: 1.1554\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4957 - loss: 1.0710 - val_accuracy: 0.1667 - val_loss: 1.1577\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4498 - loss: 1.0867 - val_accuracy: 0.2083 - val_loss: 1.1600\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4205 - loss: 1.0929 - val_accuracy: 0.2083 - val_loss: 1.1599\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3903 - loss: 1.0789 - val_accuracy: 0.2083 - val_loss: 1.1583\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4635 - loss: 1.0827 - val_accuracy: 0.2083 - val_loss: 1.1530\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5033 - loss: 1.0587 - val_accuracy: 0.2083 - val_loss: 1.1507\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4819 - loss: 1.0466 - val_accuracy: 0.2500 - val_loss: 1.1458\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3941 - loss: 1.0623 - val_accuracy: 0.2083 - val_loss: 1.1488\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5228 - loss: 1.0444 - val_accuracy: 0.2083 - val_loss: 1.1499\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3599 - loss: 1.0834 - val_accuracy: 0.2083 - val_loss: 1.1501\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 1.0992 - val_accuracy: 0.2083 - val_loss: 1.1509\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4636 - loss: 1.0652 - val_accuracy: 0.2083 - val_loss: 1.1526\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4716 - loss: 1.0563 - val_accuracy: 0.2083 - val_loss: 1.1526\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4418 - loss: 1.0714 - val_accuracy: 0.2500 - val_loss: 1.1524\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5047 - loss: 1.0744 - val_accuracy: 0.2500 - val_loss: 1.1535\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5315 - loss: 1.0335 - val_accuracy: 0.2083 - val_loss: 1.1551\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4100 - loss: 1.0678 - val_accuracy: 0.2500 - val_loss: 1.1508\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5070 - loss: 1.0599 - val_accuracy: 0.2500 - val_loss: 1.1540\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4436 - loss: 1.0670 - val_accuracy: 0.2917 - val_loss: 1.1520\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4900 - loss: 1.0518 - val_accuracy: 0.2917 - val_loss: 1.1488\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4172 - loss: 1.0845 - val_accuracy: 0.2917 - val_loss: 1.1501\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3955 - loss: 1.0553 - val_accuracy: 0.2917 - val_loss: 1.1529\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4654 - loss: 1.0405 - val_accuracy: 0.2917 - val_loss: 1.1525\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4092 - loss: 1.0540 - val_accuracy: 0.2917 - val_loss: 1.1476\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4067 - loss: 1.0513 - val_accuracy: 0.2917 - val_loss: 1.1492\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4600 - loss: 1.0634 - val_accuracy: 0.2917 - val_loss: 1.1515\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4920 - loss: 1.0238 - val_accuracy: 0.2917 - val_loss: 1.1475\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 1.0718 - val_accuracy: 0.3333 - val_loss: 1.1491\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3379 - loss: 1.0701 - val_accuracy: 0.3333 - val_loss: 1.1450\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4661 - loss: 1.0382 - val_accuracy: 0.3333 - val_loss: 1.1407\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4163 - loss: 1.0655 - val_accuracy: 0.3333 - val_loss: 1.1394\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4982 - loss: 1.0476 - val_accuracy: 0.3333 - val_loss: 1.1424\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4292 - loss: 1.0687 - val_accuracy: 0.3333 - val_loss: 1.1470\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4085 - loss: 1.0657 - val_accuracy: 0.3333 - val_loss: 1.1488\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4606 - loss: 1.0352 - val_accuracy: 0.3333 - val_loss: 1.1500\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3709 - loss: 1.0490 - val_accuracy: 0.3333 - val_loss: 1.1467\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4725 - loss: 1.0385 - val_accuracy: 0.3333 - val_loss: 1.1483\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4449 - loss: 1.0354 - val_accuracy: 0.3750 - val_loss: 1.1442\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4249 - loss: 1.0674 - val_accuracy: 0.3750 - val_loss: 1.1379\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5116 - loss: 1.0271 - val_accuracy: 0.3750 - val_loss: 1.1434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa748ae5f60>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfIhCRKnnZ0J",
        "outputId": "c37e2966-0f2d-4019-f37e-3f81e62e7ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2333 - loss: 1.1557\n",
            "Test Loss: 1.1557, Test Accuracy: 0.2333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFFMEB33nihu",
        "outputId": "3c84ec2f-9bd8-4e87-d44a-4e81c176afb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.33      0.11      0.17         9\n",
            "           2       0.25      0.09      0.13        11\n",
            "\n",
            "   micro avg       0.13      0.07      0.09        30\n",
            "   macro avg       0.19      0.07      0.10        30\n",
            "weighted avg       0.19      0.07      0.10        30\n",
            " samples avg       0.07      0.07      0.07        30\n",
            "\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "data = {\n",
        "    'user': ['User1'] * 50 + ['User2'] * 50 + ['User3'] * 50,\n",
        "    'avg_time': np.random.normal(loc=0.2, scale=0.05, size=150),\n",
        "    'std_dev_time': np.random.normal(loc=0.02, scale=0.01, size=150),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "X = df[['avg_time', 'std_dev_time']]\n",
        "y = df['user']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1500, random_state=143)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To3vxky8pKBu",
        "outputId": "8799aa18-a5ed-406d-9dd6-761d02ba1083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8 0 2]\n",
            " [4 2 3]\n",
            " [4 2 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       User1       0.50      0.80      0.62        10\n",
            "       User2       0.50      0.22      0.31         9\n",
            "       User3       0.50      0.45      0.48        11\n",
            "\n",
            "    accuracy                           0.50        30\n",
            "   macro avg       0.50      0.49      0.47        30\n",
            "weighted avg       0.50      0.50      0.47        30\n",
            "\n",
            "['User1' 'User1' 'User1' 'User3' 'User3' 'User1' 'User3' 'User1' 'User1'\n",
            " 'User2' 'User3' 'User1' 'User3' 'User1' 'User1' 'User1' 'User2' 'User2'\n",
            " 'User1' 'User1' 'User3' 'User3' 'User1' 'User1' 'User3' 'User3' 'User3'\n",
            " 'User2' 'User1' 'User1']\n"
          ]
        }
      ]
    }
  ]
}